{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 12:07:13.583149: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-01 12:07:13.627170: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-01 12:07:13.938276: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-01 12:07:13.939399: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-01 12:07:15.057848: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 288 images belonging to 2 classes.\n",
      "Found 36 images belonging to 2 classes.\n",
      "Found 180 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   validation_split=0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   validation_split=0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(r'/home/hazeeba/Documents/Luminar_internship/Parkinson/P5_Parkinson/park_img/spiral/train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 8,\n",
    "                                                 subset=\"training\",\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "validation_set = train_datagen.flow_from_directory(r'/home/hazeeba/Documents/Luminar_internship/Parkinson/P5_Parkinson/park_img/spiral/test',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 8,\n",
    "                                                subset=\"validation\",\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(r'/home/hazeeba/Documents/Luminar_internship/Parkinson/P5_Parkinson/park_img/spiral/test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 8,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "#color_mode = \"grayscale\"\n",
    "\n",
    "\n",
    "STEP_SIZE_TRAIN=training_set.n//training_set.batch_size\n",
    "STEP_SIZE_VALID=validation_set.n//validation_set.batch_size\n",
    "STEP_SIZE_TEST=test_set.n//test_set.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.preprocessing.image.DirectoryIterator at 0x7fdfd4131a30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 50178     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14764866 (56.32 MB)\n",
      "Trainable params: 50178 (196.01 KB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = [224, 224]\n",
    "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "#here [3] denotes for RGB images(3 channels)\n",
    "\n",
    "#don't train existing weights\n",
    "for layer in vgg.layers:\n",
    " layer.trainable = False\n",
    " \n",
    "x = Flatten()(vgg.output)\n",
    "prediction = Dense(2, activation='sigmoid')(x)\n",
    "model = Model(inputs=vgg.input, outputs=prediction)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                    optimizer=optimizers.Adam(),\n",
    "                    metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8123/1185727071.py:30: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.91521, saving model to mymodel.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hazeeba/.local/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/18\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.91521\n",
      "Epoch 3/18\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.91521\n",
      "Epoch 4/18\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.91521\n",
      "Epoch 5/18\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.91521\n",
      "Epoch 6/18\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.91521\n",
      "Epoch 7/18\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.91521\n",
      "Epoch 8/18\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.91521\n",
      "Epoch 9/18\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.91521\n",
      "Epoch 10/18\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.91521\n",
      "Epoch 11/18\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.91521\n",
      "Epoch 12/18\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.91521\n",
      "Epoch 13/18\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.91521\n",
      "Epoch 14/18\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.91521\n",
      "Epoch 15/18\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.91521\n",
      "Epoch 16/18\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.91521\n",
      "Epoch 17/18\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.91521\n",
      "Epoch 18/18\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.91521\n",
      "Training completed in time:  0:09:14.969422\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "checkpoint = ModelCheckpoint(filepath='mymodel.h5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "callbacks = [checkpoint, lr_reducer]\n",
    "start = datetime.now()\n",
    "# history = model.fit_generator(training_set, \n",
    "#                     steps_per_epoch=STEP_SIZE_TRAIN, \n",
    "#                     epochs = 18, verbose=5, \n",
    "#                     validation_data = validation_set, \n",
    "#                     validation_steps = STEP_SIZE_VALID)\n",
    "# duration = datetime.now() - start\n",
    "# print(\"Training completed in time: \", duration)\n",
    "\n",
    "# Assuming you have a `training_set` generator\n",
    "# and `batch_size` is the batch size used in the generator\n",
    "\n",
    "batch_size=8\n",
    "total_samples = len(training_set) * batch_size\n",
    "steps_per_epoch = total_samples // batch_size\n",
    "\n",
    "# Make sure steps_per_epoch is at least 1\n",
    "steps_per_epoch = max(steps_per_epoch, 1)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    training_set,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=18,\n",
    "    verbose=5,\n",
    "    validation_data=validation_set,\n",
    "    validation_steps=len(validation_set),  # or calculate based on validation data size\n",
    "    callbacks=[checkpoint, lr_reducer]\n",
    ")\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 17s 748ms/step - loss: 0.4102 - accuracy: 0.8778\n",
      "Test Loss: 0.41019129753112793\n",
      "Test accuracy: 0.8777777552604675\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_set)\n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 288 images belonging to 2 classes.\n",
      "Found 72 images belonging to 2 classes.\n",
      "Found 30 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image Data Generators for the \"wave\" dataset\n",
    "train_datagen_wave = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    validation_split=0.2,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "\n",
    "test_datagen_wave = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    validation_split=0.2,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "\n",
    "# Directories for the \"wave\" dataset\n",
    "train_dir_wave = r'/home/hazeeba/Documents/Luminar_internship/Parkinson/P5_Parkinson/park_img/wave/train'\n",
    "test_dir_wave = r'/home/hazeeba/Documents/Luminar_internship/Parkinson/P5_Parkinson/park_img/wave/test'\n",
    "\n",
    "# Flow from Directory for the \"wave\" dataset\n",
    "training_set_wave = train_datagen_wave.flow_from_directory(\n",
    "    train_dir_wave,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 8,\n",
    "    subset=\"training\",\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "validation_set_wave = train_datagen_wave.flow_from_directory(\n",
    "    train_dir_wave,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 8,\n",
    "    subset=\"validation\",\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "test_set_wave = test_datagen_wave.flow_from_directory(\n",
    "    test_dir_wave,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 8,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 50178     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14764866 (56.32 MB)\n",
      "Trainable params: 50178 (196.01 KB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8123/1958012368.py:37: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.98228, saving model to mymodel_wave.h5\n",
      "Epoch 2/18\n",
      "\n",
      "Epoch 2: val_loss improved from 0.98228 to 0.45682, saving model to mymodel_wave.h5\n",
      "Epoch 3/18\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.45682\n",
      "Epoch 4/18\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.45682\n",
      "Epoch 5/18\n",
      "\n",
      "Epoch 5: val_loss improved from 0.45682 to 0.36792, saving model to mymodel_wave.h5\n",
      "Epoch 6/18\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.36792\n",
      "Epoch 7/18\n",
      "\n",
      "Epoch 7: val_loss improved from 0.36792 to 0.31845, saving model to mymodel_wave.h5\n",
      "Epoch 8/18\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.31845\n",
      "Epoch 9/18\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.31845\n",
      "Epoch 10/18\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.31845\n",
      "Epoch 11/18\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.31845\n",
      "Epoch 12/18\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.31845\n",
      "Epoch 13/18\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.31845\n",
      "Epoch 14/18\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.31845\n",
      "Epoch 15/18\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.31845\n",
      "Epoch 16/18\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.31845\n",
      "Epoch 17/18\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.31845\n",
      "Epoch 18/18\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.31845\n",
      "Training completed in time:  0:10:31.489265\n"
     ]
    }
   ],
   "source": [
    "# Model Architecture\n",
    "IMAGE_SIZE = [224, 224]\n",
    "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = Flatten()(vgg.output)\n",
    "prediction = Dense(2, activation='sigmoid')(x)\n",
    "model = Model(inputs=vgg.input, outputs=prediction)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Callbacks\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                                cooldown=0,\n",
    "                                patience=5,\n",
    "                                min_lr=0.5e-6)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='mymodel_wave.h5', \n",
    "                              verbose=1, \n",
    "                              save_best_only=True)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer]\n",
    "\n",
    "# Training\n",
    "batch_size = 8\n",
    "total_samples = len(training_set_wave) * batch_size\n",
    "steps_per_epoch = total_samples // batch_size\n",
    "steps_per_epoch = max(steps_per_epoch, 1)\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "history = model.fit_generator(\n",
    "    training_set_wave,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=18,\n",
    "    verbose=5,\n",
    "    validation_data=validation_set_wave,\n",
    "    validation_steps=len(validation_set_wave),\n",
    "    callbacks=[checkpoint, lr_reducer]\n",
    ")\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 636ms/step - loss: 0.3527 - accuracy: 0.8000\n",
      "Test Loss: 0.3527430295944214\n",
      "Test accuracy: 0.800000011920929\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "score = model.evaluate(test_set_wave)\n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "Predicted Label: Parkinson\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained models\n",
    "model_spiral = load_model('mymodel.h5')  # Trained model for spiral dataset\n",
    "model_wave = load_model('mymodel_wave.h5')  # Trained model for wave dataset\n",
    "\n",
    "# Path to the new image\n",
    "new_image_path = '/home/hazeeba/Documents/Luminar_internship/Parkinson/Prediction_images/pw4.png'  # Replace with the path to your new image\n",
    "\n",
    "# Load and preprocess the new image\n",
    "new_img = image.load_img(new_image_path, target_size=(224, 224))\n",
    "new_img_array = image.img_to_array(new_img)\n",
    "new_img_array = np.expand_dims(new_img_array, axis=0)\n",
    "new_img_array /= 255.0  # Normalize the image\n",
    "\n",
    "# Make predictions using both models\n",
    "prediction_spiral = model_spiral.predict(new_img_array)\n",
    "prediction_wave = model_wave.predict(new_img_array)\n",
    "\n",
    "# Combine predictions from both models\n",
    "combined_prediction = (prediction_spiral + prediction_wave) / 2  # Take the average\n",
    "\n",
    "# Convert the combined predicted probabilities to class labels\n",
    "predicted_class = np.argmax(combined_prediction)\n",
    "\n",
    "# Define the class labels\n",
    "class_labels = ['Healthy', 'Parkinson']\n",
    "\n",
    "# Get the label of the image\n",
    "predicted_label = class_labels[predicted_class]\n",
    "\n",
    "# Display the predicted label\n",
    "print(\"Predicted Label:\", predicted_label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
